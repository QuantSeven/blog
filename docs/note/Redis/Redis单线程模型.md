# Redis单线程模型

## Redis单线程模型

 ![](/images/Redis单线程模型.png)

* 文件事件处理器

  > redis基于reactor模式开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler。这个文件事件处理器，是单线程的，redis才叫做单线程的模型，采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器来处理这个事件。
  >
  >  
  >
  > 如果被监听的socket准备好执行accept、read、write、close等操作的时候，跟操作对应的文件事件就会产生，这个时候文件事件处理器就会调用之前关联好的事件处理器来处理这个事件。
  >
  >  
  >
  > 文件事件处理器是单线程模式运行的，但是通过IO多路复用机制监听多个socket，可以实现高性能的网络通信模型，又可以跟内部其他单线程的模块进行对接，保证了redis内部的线程模型的简单性。
  >
  >  
  >
  > 文件事件处理器的结构包含4个部分：多个socket，IO多路复用程序，文件事件分派器，事件处理器（命令请求处理器、命令回复处理器、连接应答处理器，等等）。
  >
  >  
  >
  > 多个socket可能并发的产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个socket，但是会将socket放入一个队列中排队，每次从队列中取出一个socket给事件分派器，事件分派器把socket给对应的事件处理器。
  >
  >  
  >
  > 然后一个socketIOsocketsocket

* 文件事件

  > 1、当socket变得可读时（比如客户端对redis执行write操作，或者close操作），或者有新的可以应答的sccket出现时（客户端对redis执行connect操作），socket就会产生一个AE_READABLE事件。
  >
  > 2、当socket变得可写的时候（客户端对redis执行read操作），socket会产生一个AE_WRITABLE事件。
  >
  > 3、IO多路复用程序可以同时监听AE_REABLE和AE_WRITABLE两种事件，要是一个socket同时产生了AE_READABLE和AE_WRITABLE两种事件，那么文件事件分派器优先处理AE_REABLE事件，然后才是AE_WRITABLE事件。
  
* 文件事件处理器

  > 如果是客户端要连接redis，那么会为socket关联连接应答处理器
  > 如果是客户端要写数据到redis，那么会为socket关联命令请求处理器
  > 如果是客户端要从redis读数据，那么会为socket关联命令回复处理器

* 客户端与redis通信的一次流程

  >在redis启动初始化的时候，redis会将连接应答处理器跟AE_READABLE事件关联起来，接着如果一个客户端跟redis发起连接，此时会产生一个AE_READABLE事件，然后由连接应答处理器来处理跟客户端建立连接，创建客户端对应的socket，同时将这个socket的AE_READABLE事件跟命令请求处理器关联起来。
  >
  > 
  >
  >当客户端向redis发起请求的时候（不管是读请求还是写请求，都一样），首先就会在socket产生一个AE_READABLE事件，然后由对应的命令请求处理器来处理。这个命令请求处理器就会从socket中读取请求相关数据，然后进行执行和处理。
  > 
  > 
  >
  >接着redis这边准备好了给客户端的响应数据之后，就会将socket的AE_WRITABLE事件跟命令回复处理器关联起来，当客户端这边准备好读取响应数据时，就会在socket上产生一个AE_WRITABLE事件，会由对应的命令回复处理器来处理，就是将准备好的响应数据写入socket，供客户端来读取。
  >
  > 
  >
  >命令回复处理器写完之后，就会删除这个socket的AE_WRITABLE事件和命令回复处理器的关联关系。



## 为啥redis单线程模型也能效率这么高？

* 纯内存操作

* 核心是基于非阻塞的IO多路复用机制

* 单线程反而避免了多线程的频繁上下文切换问题

  * **一、多线程给我们带来的代价** 

    * 设计更复杂

      > 多线程程序在访问共享数据的时候往往需要我们很小心的处理,否则就会出现难以发现的BUG，一般地，多线程程序往往比单线程程序设计会更加复杂（尽管有些单线程处理程序可能比多线程程序要复杂），而且错误很难重现（因为线程调度的无序性，某些bug的出现依赖于某种特定的线程执行时序）。 

    * 上下文切换的开销

      > 线程是由CPU进行调度的，CPU的一个时间片内只执行一个线程上下文内的线程，当CPU由执行线程A切换到执行线程B的过程中会发生一些列的操作，这些操作主要有”保存线程A的执行现场“然后”载入线程B的执行现场”，这个过程称之为“上下文切换（context switch）”,这个上下文切换过程并不廉价，如果没有必要，应该尽量减少上下文切换的发生

    * 增加更多的资源消耗

      >  除了CPU执行上下文切换的消耗以外，线程的执行还将有其他一些资源的消耗，比如:内存同步的开销（线程需要一些内存在维持线程本地栈,每个线程都有本地独立的栈用以存储线程专用数据），上下文切换的开销（前面已经讲过），线程创建和消亡的开销，以及调度的开销（占用操作系统的一些资源来管理和协调线程），我们可以创建100个线程让他们什么都不做，看看他们消耗了多少内存。

  * **二、上下文切换**

    > ​    多数人认为使用多线程一定会比单线程执行速度快，但其实未必，因为多线程应用程序会带来额外的开销和竞争问题，他们都可能会拖慢系统的执行速度。这些因素包括：对IO设备的竞争，对锁的竞争，以及CPU对线程执行上下文的频繁切换等。
    >
    > 目前流行的CPU在同一时间内只能运行一个线程，超线程的处理器（包括多核处理器）可以同一时间运行多个线程，linux将多核处理器当作多个单独CPU来识别的。每个进程都会分到CPU的时间片来运行，当某个进程（线程是轻量级进程，他们是可以并行运行的，并且共享地使用他们所属进程的地址空间资源，比如：内存空间或其他资源）当进程用完时间片或者被另一个优先级更高的进程抢占的时候，CPU会将该进程备份到CPU的运行队列中，其他进程被调度在CPU上运行，这个进程切换的过程被称作“上下文切换”，过多的上下文切换会造成系统很大的开销。
    >
    > ​    在Linux中可以使用vmstat来观察上下文切换的次数，一般来说，空闲的系统，每秒上下文切换次数大概在1500以下。
    >
    > ​    引起上下文切换的原因:
    >
    > ​     1、时间片用完，CPU正常调度下一个任务
    >
    > ​     2、被其他优先级更高的任务抢占
    >
    > ​     3、执行任务碰到IO阻塞，调度器挂起当前任务，切换执行下一个任务
    >
    > ​     4、用户代码主动挂起当前任务让出CPU时间
    >
    > ​     5、多任务抢占资源，由于没有抢到被挂起
    >
    > ​     6、硬件中断

